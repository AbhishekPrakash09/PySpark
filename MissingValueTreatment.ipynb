{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a211ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c712d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('Salary.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85db0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|Abhishek|  41|        17|  2000|\n",
      "| Akansha|  36|        10|  2500|\n",
      "|   Akash|  35|        10|  2600|\n",
      "|  Prince|  30|         7|  1850|\n",
      "|  Shweta|  31|         7|  2150|\n",
      "|    Ivan|null|      null|  2200|\n",
      "|    null|  30|         4|  1200|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9564295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|Abhishek| 41|        17|  2000|\n",
      "| Akansha| 36|        10|  2500|\n",
      "|   Akash| 35|        10|  2600|\n",
      "|  Prince| 30|         7|  1850|\n",
      "|  Shweta| 31|         7|  2150|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5480a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|Abhishek|  41|        17|  2000|\n",
      "| Akansha|  36|        10|  2500|\n",
      "|   Akash|  35|        10|  2600|\n",
      "|  Prince|  30|         7|  1850|\n",
      "|  Shweta|  31|         7|  2150|\n",
      "|    Ivan|null|      null|  2200|\n",
      "|    null|  30|         4|  1200|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.dropna(how='all').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655efe8d",
   "metadata": {},
   "source": [
    "<font color = 'Blue'>Note: how='all' will drop those rows where all values are null </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a88cd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|Abhishek| 41|        17|  2000|\n",
      "| Akansha| 36|        10|  2500|\n",
      "|   Akash| 35|        10|  2600|\n",
      "|  Prince| 30|         7|  1850|\n",
      "|  Shweta| 31|         7|  2150|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.dropna(how='any').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3842c",
   "metadata": {},
   "source": [
    "<font color = 'Blue'> Note: how='any' will drop those rows where all values are null </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36366f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|Abhishek|  41|        17|  2000|\n",
      "| Akansha|  36|        10|  2500|\n",
      "|   Akash|  35|        10|  2600|\n",
      "|  Prince|  30|         7|  1850|\n",
      "|  Shweta|  31|         7|  2150|\n",
      "|    Ivan|null|      null|  2200|\n",
      "|    null|  30|         4|  1200|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.dropna(how='any', thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f32b690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|Abhishek| 41|        17|  2000|\n",
      "| Akansha| 36|        10|  2500|\n",
      "|   Akash| 35|        10|  2600|\n",
      "|  Prince| 30|         7|  1850|\n",
      "|  Shweta| 31|         7|  2150|\n",
      "|    null| 30|         4|  1200|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any', thresh=3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc69f3e",
   "metadata": {},
   "source": [
    "<font color = 'Blue'> Note: how='any', thresh=3 drops rows with less than 3 non-null values. Also, dropna() works the same as na.drop() </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ae2a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|Abhishek|  41|        17|  2000|\n",
      "| Akansha|  36|        10|  2500|\n",
      "|   Akash|  35|        10|  2600|\n",
      "|  Prince|  30|         7|  1850|\n",
      "|  Shweta|  31|         7|  2150|\n",
      "|    Ivan|null|      null|  2200|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.dropna(how='any', subset=['Name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf84b2",
   "metadata": {},
   "source": [
    "<font color = 'Blue'> Note: how='any', subset = 'Name', drops all rows where Name = null </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e40811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+----------+------+\n",
      "|             Name| Age|Experience|Salary|\n",
      "+-----------------+----+----------+------+\n",
      "|         Abhishek|  41|        17|  2000|\n",
      "|          Akansha|  36|        10|  2500|\n",
      "|            Akash|  35|        10|  2600|\n",
      "|           Prince|  30|         7|  1850|\n",
      "|           Shweta|  31|         7|  2150|\n",
      "|             Ivan|null|      null|  2200|\n",
      "|No Name Available|  30|         4|  1200|\n",
      "+-----------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.fillna('No Name Available', ['Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf824a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['Age', 'Experience', 'Salary'],\n",
    "                  outputCols = ['{}_imputed'.format(column) for column in ['Age', 'Experience', 'Salary']]\n",
    "                 ).setStrategy('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf077dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|Abhishek|  41|        17|  2000|         41|                17|          2000|\n",
      "| Akansha|  36|        10|  2500|         36|                10|          2500|\n",
      "|   Akash|  35|        10|  2600|         35|                10|          2600|\n",
      "|  Prince|  30|         7|  1850|         30|                 7|          1850|\n",
      "|  Shweta|  31|         7|  2150|         31|                 7|          2150|\n",
      "|    Ivan|null|      null|  2200|         31|                 7|          2200|\n",
      "|    null|  30|         4|  1200|         30|                 4|          1200|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248989b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
